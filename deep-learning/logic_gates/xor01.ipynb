{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "y: (4,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from libs.simple_processing import separate_target\n",
    "\n",
    "DATA = pd.read_csv('xor.csv', delimiter=';')\n",
    "\n",
    "X, y = separate_target(DATA, 'y')\n",
    "\n",
    "print(X.shape)\n",
    "print('y:', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "(4, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# patience below 7 cuts to early\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.0005,  # minimium amount of change to count as an improvement\n",
    "    patience=7,  # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.6, random_state=40)\n",
    "\n",
    "X_train = X.copy()\n",
    "y_train = y.copy()\n",
    "X_valid = X.copy()\n",
    "y_valid = y.copy()\n",
    "\n",
    "input_shape = [X_train.shape[1]]\n",
    "print(input_shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x1  x2\n",
      "0   0   0\n",
      "1   0   1\n",
      "2   1   0\n",
      "3   1   1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 16:40:58.219060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 829ms/step - loss: 0.7342 - binary_accuracy: 0.5000 - val_loss: 0.6782 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6782 - binary_accuracy: 0.5000 - val_loss: 0.6404 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6404 - binary_accuracy: 0.5000 - val_loss: 0.6105 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/450\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6105 - binary_accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 16:40:58.722840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6105 - binary_accuracy: 0.5000 - val_loss: 0.5852 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5852 - binary_accuracy: 0.5000 - val_loss: 0.5629 - val_binary_accuracy: 0.5000\n",
      "Epoch 6/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5629 - binary_accuracy: 0.5000 - val_loss: 0.5428 - val_binary_accuracy: 0.5000\n",
      "Epoch 7/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5428 - binary_accuracy: 0.5000 - val_loss: 0.5245 - val_binary_accuracy: 0.5000\n",
      "Epoch 8/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5245 - binary_accuracy: 0.5000 - val_loss: 0.5076 - val_binary_accuracy: 0.5000\n",
      "Epoch 9/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5076 - binary_accuracy: 0.5000 - val_loss: 0.4918 - val_binary_accuracy: 0.5000\n",
      "Epoch 10/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4918 - binary_accuracy: 0.5000 - val_loss: 0.4770 - val_binary_accuracy: 0.5000\n",
      "Epoch 11/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4770 - binary_accuracy: 0.5000 - val_loss: 0.4630 - val_binary_accuracy: 0.5000\n",
      "Epoch 12/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4630 - binary_accuracy: 0.5000 - val_loss: 0.4498 - val_binary_accuracy: 0.5000\n",
      "Epoch 13/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4498 - binary_accuracy: 0.5000 - val_loss: 0.4372 - val_binary_accuracy: 0.5000\n",
      "Epoch 14/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4372 - binary_accuracy: 0.5000 - val_loss: 0.4252 - val_binary_accuracy: 0.5000\n",
      "Epoch 15/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4252 - binary_accuracy: 0.5000 - val_loss: 0.4137 - val_binary_accuracy: 0.5000\n",
      "Epoch 16/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4137 - binary_accuracy: 0.5000 - val_loss: 0.4028 - val_binary_accuracy: 0.5000\n",
      "Epoch 17/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4028 - binary_accuracy: 0.5000 - val_loss: 0.3923 - val_binary_accuracy: 0.5000\n",
      "Epoch 18/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3923 - binary_accuracy: 0.5000 - val_loss: 0.3822 - val_binary_accuracy: 0.5000\n",
      "Epoch 19/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3822 - binary_accuracy: 0.5000 - val_loss: 0.3725 - val_binary_accuracy: 0.5000\n",
      "Epoch 20/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3725 - binary_accuracy: 0.5000 - val_loss: 0.3633 - val_binary_accuracy: 0.5000\n",
      "Epoch 21/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3633 - binary_accuracy: 0.5000 - val_loss: 0.3543 - val_binary_accuracy: 0.5000\n",
      "Epoch 22/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3543 - binary_accuracy: 0.5000 - val_loss: 0.3457 - val_binary_accuracy: 0.5000\n",
      "Epoch 23/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3457 - binary_accuracy: 0.5000 - val_loss: 0.3374 - val_binary_accuracy: 0.5000\n",
      "Epoch 24/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3374 - binary_accuracy: 0.5000 - val_loss: 0.3295 - val_binary_accuracy: 0.5000\n",
      "Epoch 25/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3295 - binary_accuracy: 0.5000 - val_loss: 0.3218 - val_binary_accuracy: 0.5000\n",
      "Epoch 26/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3218 - binary_accuracy: 0.5000 - val_loss: 0.3145 - val_binary_accuracy: 0.5000\n",
      "Epoch 27/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3145 - binary_accuracy: 0.5000 - val_loss: 0.3074 - val_binary_accuracy: 0.5000\n",
      "Epoch 28/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3074 - binary_accuracy: 0.5000 - val_loss: 0.3005 - val_binary_accuracy: 0.5000\n",
      "Epoch 29/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3005 - binary_accuracy: 0.5000 - val_loss: 0.2940 - val_binary_accuracy: 0.5000\n",
      "Epoch 30/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2940 - binary_accuracy: 0.5000 - val_loss: 0.2877 - val_binary_accuracy: 0.5000\n",
      "Epoch 31/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2877 - binary_accuracy: 0.5000 - val_loss: 0.2816 - val_binary_accuracy: 0.5000\n",
      "Epoch 32/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2816 - binary_accuracy: 0.5000 - val_loss: 0.2758 - val_binary_accuracy: 0.5000\n",
      "Epoch 33/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2758 - binary_accuracy: 0.5000 - val_loss: 0.2702 - val_binary_accuracy: 0.5000\n",
      "Epoch 34/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2702 - binary_accuracy: 0.5000 - val_loss: 0.2648 - val_binary_accuracy: 0.5000\n",
      "Epoch 35/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2648 - binary_accuracy: 0.5000 - val_loss: 0.2597 - val_binary_accuracy: 0.5000\n",
      "Epoch 36/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2597 - binary_accuracy: 0.5000 - val_loss: 0.2548 - val_binary_accuracy: 0.5000\n",
      "Epoch 37/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2548 - binary_accuracy: 0.5000 - val_loss: 0.2501 - val_binary_accuracy: 0.5000\n",
      "Epoch 38/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2501 - binary_accuracy: 0.5000 - val_loss: 0.2456 - val_binary_accuracy: 0.5000\n",
      "Epoch 39/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2456 - binary_accuracy: 0.5000 - val_loss: 0.2413 - val_binary_accuracy: 0.5000\n",
      "Epoch 40/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2413 - binary_accuracy: 0.5000 - val_loss: 0.2372 - val_binary_accuracy: 0.7500\n",
      "Epoch 41/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2372 - binary_accuracy: 0.7500 - val_loss: 0.2333 - val_binary_accuracy: 0.7500\n",
      "Epoch 42/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2333 - binary_accuracy: 0.7500 - val_loss: 0.2296 - val_binary_accuracy: 0.7500\n",
      "Epoch 43/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2296 - binary_accuracy: 0.7500 - val_loss: 0.2261 - val_binary_accuracy: 0.7500\n",
      "Epoch 44/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2261 - binary_accuracy: 0.7500 - val_loss: 0.2227 - val_binary_accuracy: 0.7500\n",
      "Epoch 45/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2227 - binary_accuracy: 0.7500 - val_loss: 0.2195 - val_binary_accuracy: 0.7500\n",
      "Epoch 46/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2195 - binary_accuracy: 0.7500 - val_loss: 0.2164 - val_binary_accuracy: 0.7500\n",
      "Epoch 47/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2164 - binary_accuracy: 0.7500 - val_loss: 0.2130 - val_binary_accuracy: 0.7500\n",
      "Epoch 48/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2130 - binary_accuracy: 0.7500 - val_loss: 0.2098 - val_binary_accuracy: 0.7500\n",
      "Epoch 49/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2098 - binary_accuracy: 0.7500 - val_loss: 0.2069 - val_binary_accuracy: 0.7500\n",
      "Epoch 50/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2069 - binary_accuracy: 0.7500 - val_loss: 0.2041 - val_binary_accuracy: 0.7500\n",
      "Epoch 51/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2041 - binary_accuracy: 0.7500 - val_loss: 0.2016 - val_binary_accuracy: 0.7500\n",
      "Epoch 52/450\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2016 - binary_accuracy: 0.7500 - val_loss: 0.1992 - val_binary_accuracy: 0.7500\n",
      "Epoch 53/450\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1992 - binary_accuracy: 0.7500 - val_loss: 0.1969 - val_binary_accuracy: 0.7500\n",
      "Epoch 54/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1969 - binary_accuracy: 0.7500 - val_loss: 0.1948 - val_binary_accuracy: 0.7500\n",
      "Epoch 55/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1948 - binary_accuracy: 0.7500 - val_loss: 0.1929 - val_binary_accuracy: 0.7500\n",
      "Epoch 56/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1929 - binary_accuracy: 0.7500 - val_loss: 0.1910 - val_binary_accuracy: 0.7500\n",
      "Epoch 57/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1910 - binary_accuracy: 0.7500 - val_loss: 0.1893 - val_binary_accuracy: 0.7500\n",
      "Epoch 58/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1893 - binary_accuracy: 0.7500 - val_loss: 0.1876 - val_binary_accuracy: 0.7500\n",
      "Epoch 59/450\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1876 - binary_accuracy: 0.7500 - val_loss: 0.1861 - val_binary_accuracy: 0.7500\n",
      "Epoch 60/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1861 - binary_accuracy: 0.7500 - val_loss: 0.1847 - val_binary_accuracy: 0.7500\n",
      "Epoch 61/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1847 - binary_accuracy: 0.7500 - val_loss: 0.1834 - val_binary_accuracy: 0.7500\n",
      "Epoch 62/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1834 - binary_accuracy: 0.7500 - val_loss: 0.1824 - val_binary_accuracy: 0.7500\n",
      "Epoch 63/450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1824 - binary_accuracy: 0.7500 - val_loss: 0.1814 - val_binary_accuracy: 0.7500\n",
      "Epoch 64/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1814 - binary_accuracy: 0.7500 - val_loss: 0.1804 - val_binary_accuracy: 0.7500\n",
      "Epoch 65/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1804 - binary_accuracy: 0.7500 - val_loss: 0.1795 - val_binary_accuracy: 0.7500\n",
      "Epoch 66/450\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1795 - binary_accuracy: 0.7500 - val_loss: 0.1787 - val_binary_accuracy: 0.7500\n",
      "Epoch 67/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1787 - binary_accuracy: 0.7500 - val_loss: 0.1779 - val_binary_accuracy: 0.7500\n",
      "Epoch 68/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1779 - binary_accuracy: 0.7500 - val_loss: 0.1771 - val_binary_accuracy: 0.7500\n",
      "Epoch 69/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1771 - binary_accuracy: 0.7500 - val_loss: 0.1763 - val_binary_accuracy: 0.7500\n",
      "Epoch 70/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1763 - binary_accuracy: 0.7500 - val_loss: 0.1756 - val_binary_accuracy: 0.7500\n",
      "Epoch 71/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1756 - binary_accuracy: 0.7500 - val_loss: 0.1749 - val_binary_accuracy: 0.7500\n",
      "Epoch 72/450\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1749 - binary_accuracy: 0.7500 - val_loss: 0.1741 - val_binary_accuracy: 0.7500\n",
      "Epoch 73/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1741 - binary_accuracy: 0.7500 - val_loss: 0.1735 - val_binary_accuracy: 0.7500\n",
      "Epoch 74/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1735 - binary_accuracy: 0.7500 - val_loss: 0.1728 - val_binary_accuracy: 0.7500\n",
      "Epoch 75/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1728 - binary_accuracy: 0.7500 - val_loss: 0.1721 - val_binary_accuracy: 0.7500\n",
      "Epoch 76/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1721 - binary_accuracy: 0.7500 - val_loss: 0.1715 - val_binary_accuracy: 0.7500\n",
      "Epoch 77/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1715 - binary_accuracy: 0.7500 - val_loss: 0.1709 - val_binary_accuracy: 0.7500\n",
      "Epoch 78/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1709 - binary_accuracy: 0.7500 - val_loss: 0.1702 - val_binary_accuracy: 0.7500\n",
      "Epoch 79/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1702 - binary_accuracy: 0.7500 - val_loss: 0.1696 - val_binary_accuracy: 0.7500\n",
      "Epoch 80/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1696 - binary_accuracy: 0.7500 - val_loss: 0.1690 - val_binary_accuracy: 0.7500\n",
      "Epoch 81/450\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1690 - binary_accuracy: 0.7500 - val_loss: 0.1683 - val_binary_accuracy: 0.7500\n",
      "Epoch 82/450\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1683 - binary_accuracy: 0.7500 - val_loss: 0.1677 - val_binary_accuracy: 0.7500\n",
      "Epoch 83/450\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1677 - binary_accuracy: 0.7500 - val_loss: 0.1671 - val_binary_accuracy: 0.7500\n",
      "Epoch 84/450\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1671 - binary_accuracy: 0.7500 - val_loss: 0.1665 - val_binary_accuracy: 0.7500\n",
      "Epoch 85/450\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1665 - binary_accuracy: 0.7500 - val_loss: 0.1659 - val_binary_accuracy: 0.7500\n",
      "Epoch 86/450\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1659 - binary_accuracy: 0.7500 - val_loss: 0.1653 - val_binary_accuracy: 0.7500\n",
      "Epoch 87/450\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1653 - binary_accuracy: 0.7500 - val_loss: 0.1647 - val_binary_accuracy: 0.7500\n",
      "Epoch 88/450\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1647 - binary_accuracy: 0.7500 - val_loss: 0.1642 - val_binary_accuracy: 0.7500\n",
      "Epoch 89/450\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1642 - binary_accuracy: 0.7500 - val_loss: 0.1636 - val_binary_accuracy: 0.7500\n",
      "Epoch 90/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1636 - binary_accuracy: 0.7500 - val_loss: 0.1630 - val_binary_accuracy: 0.7500\n",
      "Epoch 91/450\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1630 - binary_accuracy: 0.7500 - val_loss: 0.1624 - val_binary_accuracy: 0.7500\n",
      "Epoch 92/450\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1624 - binary_accuracy: 0.7500 - val_loss: 0.1619 - val_binary_accuracy: 0.7500\n",
      "Epoch 93/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1619 - binary_accuracy: 0.7500 - val_loss: 0.1613 - val_binary_accuracy: 0.7500\n",
      "Epoch 94/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1613 - binary_accuracy: 0.7500 - val_loss: 0.1607 - val_binary_accuracy: 0.7500\n",
      "Epoch 95/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1607 - binary_accuracy: 0.7500 - val_loss: 0.1602 - val_binary_accuracy: 0.7500\n",
      "Epoch 96/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1602 - binary_accuracy: 0.7500 - val_loss: 0.1596 - val_binary_accuracy: 0.7500\n",
      "Epoch 97/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1596 - binary_accuracy: 0.7500 - val_loss: 0.1591 - val_binary_accuracy: 0.7500\n",
      "Epoch 98/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1591 - binary_accuracy: 0.7500 - val_loss: 0.1585 - val_binary_accuracy: 0.7500\n",
      "Epoch 99/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1585 - binary_accuracy: 0.7500 - val_loss: 0.1580 - val_binary_accuracy: 0.7500\n",
      "Epoch 100/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1580 - binary_accuracy: 0.7500 - val_loss: 0.1574 - val_binary_accuracy: 0.7500\n",
      "Epoch 101/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1574 - binary_accuracy: 0.7500 - val_loss: 0.1569 - val_binary_accuracy: 0.7500\n",
      "Epoch 102/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1569 - binary_accuracy: 0.7500 - val_loss: 0.1564 - val_binary_accuracy: 0.7500\n",
      "Epoch 103/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1564 - binary_accuracy: 0.7500 - val_loss: 0.1558 - val_binary_accuracy: 0.7500\n",
      "Epoch 104/450\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1558 - binary_accuracy: 0.7500 - val_loss: 0.1553 - val_binary_accuracy: 0.7500\n",
      "Epoch 105/450\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1553 - binary_accuracy: 0.7500 - val_loss: 0.1548 - val_binary_accuracy: 0.7500\n",
      "Epoch 106/450\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1548 - binary_accuracy: 0.7500 - val_loss: 0.1542 - val_binary_accuracy: 0.7500\n",
      "Epoch 107/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1542 - binary_accuracy: 0.7500 - val_loss: 0.1537 - val_binary_accuracy: 0.7500\n",
      "Epoch 108/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1537 - binary_accuracy: 0.7500 - val_loss: 0.1532 - val_binary_accuracy: 0.7500\n",
      "Epoch 109/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1532 - binary_accuracy: 0.7500 - val_loss: 0.1526 - val_binary_accuracy: 0.7500\n",
      "Epoch 110/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1526 - binary_accuracy: 0.7500 - val_loss: 0.1521 - val_binary_accuracy: 0.7500\n",
      "Epoch 111/450\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1521 - binary_accuracy: 0.7500 - val_loss: 0.1516 - val_binary_accuracy: 0.7500\n",
      "Epoch 112/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1516 - binary_accuracy: 0.7500 - val_loss: 0.1511 - val_binary_accuracy: 0.7500\n",
      "Epoch 113/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1511 - binary_accuracy: 0.7500 - val_loss: 0.1505 - val_binary_accuracy: 0.7500\n",
      "Epoch 114/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1505 - binary_accuracy: 0.7500 - val_loss: 0.1500 - val_binary_accuracy: 0.7500\n",
      "Epoch 115/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1500 - binary_accuracy: 0.7500 - val_loss: 0.1495 - val_binary_accuracy: 0.7500\n",
      "Epoch 116/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1495 - binary_accuracy: 0.7500 - val_loss: 0.1490 - val_binary_accuracy: 0.7500\n",
      "Epoch 117/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1490 - binary_accuracy: 0.7500 - val_loss: 0.1485 - val_binary_accuracy: 0.7500\n",
      "Epoch 118/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1485 - binary_accuracy: 0.7500 - val_loss: 0.1480 - val_binary_accuracy: 0.7500\n",
      "Epoch 119/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1480 - binary_accuracy: 0.7500 - val_loss: 0.1474 - val_binary_accuracy: 0.7500\n",
      "Epoch 120/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1474 - binary_accuracy: 0.7500 - val_loss: 0.1469 - val_binary_accuracy: 0.7500\n",
      "Epoch 121/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1469 - binary_accuracy: 0.7500 - val_loss: 0.1464 - val_binary_accuracy: 0.7500\n",
      "Epoch 122/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1464 - binary_accuracy: 0.7500 - val_loss: 0.1459 - val_binary_accuracy: 0.7500\n",
      "Epoch 123/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1459 - binary_accuracy: 0.7500 - val_loss: 0.1454 - val_binary_accuracy: 0.7500\n",
      "Epoch 124/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1454 - binary_accuracy: 0.7500 - val_loss: 0.1449 - val_binary_accuracy: 0.7500\n",
      "Epoch 125/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1449 - binary_accuracy: 0.7500 - val_loss: 0.1444 - val_binary_accuracy: 0.7500\n",
      "Epoch 126/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1444 - binary_accuracy: 0.7500 - val_loss: 0.1439 - val_binary_accuracy: 0.7500\n",
      "Epoch 127/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1439 - binary_accuracy: 0.7500 - val_loss: 0.1434 - val_binary_accuracy: 0.7500\n",
      "Epoch 128/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1434 - binary_accuracy: 0.7500 - val_loss: 0.1430 - val_binary_accuracy: 0.7500\n",
      "Epoch 129/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1430 - binary_accuracy: 0.7500 - val_loss: 0.1425 - val_binary_accuracy: 0.7500\n",
      "Epoch 130/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1425 - binary_accuracy: 0.7500 - val_loss: 0.1420 - val_binary_accuracy: 0.7500\n",
      "Epoch 131/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1420 - binary_accuracy: 0.7500 - val_loss: 0.1415 - val_binary_accuracy: 0.7500\n",
      "Epoch 132/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1415 - binary_accuracy: 0.7500 - val_loss: 0.1410 - val_binary_accuracy: 0.7500\n",
      "Epoch 133/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1410 - binary_accuracy: 0.7500 - val_loss: 0.1405 - val_binary_accuracy: 0.7500\n",
      "Epoch 134/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1405 - binary_accuracy: 0.7500 - val_loss: 0.1400 - val_binary_accuracy: 0.7500\n",
      "Epoch 135/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1400 - binary_accuracy: 0.7500 - val_loss: 0.1396 - val_binary_accuracy: 0.7500\n",
      "Epoch 136/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1396 - binary_accuracy: 0.7500 - val_loss: 0.1391 - val_binary_accuracy: 0.7500\n",
      "Epoch 137/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1391 - binary_accuracy: 0.7500 - val_loss: 0.1386 - val_binary_accuracy: 0.7500\n",
      "Epoch 138/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1386 - binary_accuracy: 0.7500 - val_loss: 0.1381 - val_binary_accuracy: 0.7500\n",
      "Epoch 139/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1381 - binary_accuracy: 0.7500 - val_loss: 0.1376 - val_binary_accuracy: 0.7500\n",
      "Epoch 140/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1376 - binary_accuracy: 0.7500 - val_loss: 0.1372 - val_binary_accuracy: 0.7500\n",
      "Epoch 141/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1372 - binary_accuracy: 0.7500 - val_loss: 0.1367 - val_binary_accuracy: 0.7500\n",
      "Epoch 142/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1367 - binary_accuracy: 0.7500 - val_loss: 0.1362 - val_binary_accuracy: 0.7500\n",
      "Epoch 143/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1362 - binary_accuracy: 0.7500 - val_loss: 0.1357 - val_binary_accuracy: 0.7500\n",
      "Epoch 144/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1357 - binary_accuracy: 0.7500 - val_loss: 0.1353 - val_binary_accuracy: 0.7500\n",
      "Epoch 145/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1353 - binary_accuracy: 0.7500 - val_loss: 0.1349 - val_binary_accuracy: 0.7500\n",
      "Epoch 146/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1349 - binary_accuracy: 0.7500 - val_loss: 0.1345 - val_binary_accuracy: 0.7500\n",
      "Epoch 147/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1345 - binary_accuracy: 0.7500 - val_loss: 0.1342 - val_binary_accuracy: 0.7500\n",
      "Epoch 148/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1342 - binary_accuracy: 0.7500 - val_loss: 0.1338 - val_binary_accuracy: 0.7500\n",
      "Epoch 149/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1338 - binary_accuracy: 0.7500 - val_loss: 0.1336 - val_binary_accuracy: 0.7500\n",
      "Epoch 150/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1336 - binary_accuracy: 0.7500 - val_loss: 0.1333 - val_binary_accuracy: 0.7500\n",
      "Epoch 151/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1333 - binary_accuracy: 0.7500 - val_loss: 0.1329 - val_binary_accuracy: 0.7500\n",
      "Epoch 152/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1329 - binary_accuracy: 0.7500 - val_loss: 0.1324 - val_binary_accuracy: 0.7500\n",
      "Epoch 153/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1324 - binary_accuracy: 0.7500 - val_loss: 0.1321 - val_binary_accuracy: 0.7500\n",
      "Epoch 154/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1321 - binary_accuracy: 0.7500 - val_loss: 0.1317 - val_binary_accuracy: 0.7500\n",
      "Epoch 155/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1317 - binary_accuracy: 0.7500 - val_loss: 0.1313 - val_binary_accuracy: 0.7500\n",
      "Epoch 156/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1313 - binary_accuracy: 0.7500 - val_loss: 0.1310 - val_binary_accuracy: 0.7500\n",
      "Epoch 157/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1310 - binary_accuracy: 0.7500 - val_loss: 0.1306 - val_binary_accuracy: 0.7500\n",
      "Epoch 158/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1306 - binary_accuracy: 0.7500 - val_loss: 0.1303 - val_binary_accuracy: 0.7500\n",
      "Epoch 159/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1303 - binary_accuracy: 0.7500 - val_loss: 0.1299 - val_binary_accuracy: 0.7500\n",
      "Epoch 160/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1299 - binary_accuracy: 0.7500 - val_loss: 0.1295 - val_binary_accuracy: 0.7500\n",
      "Epoch 161/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1295 - binary_accuracy: 0.7500 - val_loss: 0.1292 - val_binary_accuracy: 0.7500\n",
      "Epoch 162/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1292 - binary_accuracy: 0.7500 - val_loss: 0.1288 - val_binary_accuracy: 0.7500\n",
      "Epoch 163/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1288 - binary_accuracy: 0.7500 - val_loss: 0.1284 - val_binary_accuracy: 0.7500\n",
      "Epoch 164/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1284 - binary_accuracy: 0.7500 - val_loss: 0.1281 - val_binary_accuracy: 0.7500\n",
      "Epoch 165/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1281 - binary_accuracy: 0.7500 - val_loss: 0.1277 - val_binary_accuracy: 0.7500\n",
      "Epoch 166/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1277 - binary_accuracy: 0.7500 - val_loss: 0.1273 - val_binary_accuracy: 0.7500\n",
      "Epoch 167/450\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1273 - binary_accuracy: 0.7500 - val_loss: 0.1270 - val_binary_accuracy: 0.7500\n",
      "Epoch 168/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1270 - binary_accuracy: 0.7500 - val_loss: 0.1266 - val_binary_accuracy: 0.7500\n",
      "Epoch 169/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1266 - binary_accuracy: 0.7500 - val_loss: 0.1262 - val_binary_accuracy: 0.7500\n",
      "Epoch 170/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1262 - binary_accuracy: 0.7500 - val_loss: 0.1258 - val_binary_accuracy: 0.7500\n",
      "Epoch 171/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1258 - binary_accuracy: 0.7500 - val_loss: 0.1254 - val_binary_accuracy: 0.7500\n",
      "Epoch 172/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1254 - binary_accuracy: 0.7500 - val_loss: 0.1250 - val_binary_accuracy: 0.7500\n",
      "Epoch 173/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1250 - binary_accuracy: 0.7500 - val_loss: 0.1246 - val_binary_accuracy: 0.7500\n",
      "Epoch 174/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1246 - binary_accuracy: 0.7500 - val_loss: 0.1243 - val_binary_accuracy: 0.7500\n",
      "Epoch 175/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1243 - binary_accuracy: 0.7500 - val_loss: 0.1239 - val_binary_accuracy: 0.7500\n",
      "Epoch 176/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1239 - binary_accuracy: 0.7500 - val_loss: 0.1235 - val_binary_accuracy: 0.7500\n",
      "Epoch 177/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1235 - binary_accuracy: 0.7500 - val_loss: 0.1231 - val_binary_accuracy: 0.7500\n",
      "Epoch 178/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1231 - binary_accuracy: 0.7500 - val_loss: 0.1227 - val_binary_accuracy: 0.7500\n",
      "Epoch 179/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1227 - binary_accuracy: 0.7500 - val_loss: 0.1223 - val_binary_accuracy: 0.7500\n",
      "Epoch 180/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1223 - binary_accuracy: 0.7500 - val_loss: 0.1219 - val_binary_accuracy: 0.7500\n",
      "Epoch 181/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1219 - binary_accuracy: 0.7500 - val_loss: 0.1216 - val_binary_accuracy: 0.7500\n",
      "Epoch 182/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1216 - binary_accuracy: 0.7500 - val_loss: 0.1212 - val_binary_accuracy: 0.7500\n",
      "Epoch 183/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1212 - binary_accuracy: 0.7500 - val_loss: 0.1208 - val_binary_accuracy: 0.7500\n",
      "Epoch 184/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1208 - binary_accuracy: 0.7500 - val_loss: 0.1204 - val_binary_accuracy: 0.7500\n",
      "Epoch 185/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1204 - binary_accuracy: 0.7500 - val_loss: 0.1200 - val_binary_accuracy: 0.7500\n",
      "Epoch 186/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1200 - binary_accuracy: 0.7500 - val_loss: 0.1195 - val_binary_accuracy: 0.7500\n",
      "Epoch 187/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1195 - binary_accuracy: 0.7500 - val_loss: 0.1191 - val_binary_accuracy: 0.7500\n",
      "Epoch 188/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1191 - binary_accuracy: 0.7500 - val_loss: 0.1187 - val_binary_accuracy: 0.7500\n",
      "Epoch 189/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1187 - binary_accuracy: 0.7500 - val_loss: 0.1183 - val_binary_accuracy: 0.7500\n",
      "Epoch 190/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1183 - binary_accuracy: 0.7500 - val_loss: 0.1179 - val_binary_accuracy: 0.7500\n",
      "Epoch 191/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1179 - binary_accuracy: 0.7500 - val_loss: 0.1175 - val_binary_accuracy: 0.7500\n",
      "Epoch 192/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1175 - binary_accuracy: 0.7500 - val_loss: 0.1171 - val_binary_accuracy: 0.7500\n",
      "Epoch 193/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1171 - binary_accuracy: 0.7500 - val_loss: 0.1167 - val_binary_accuracy: 0.7500\n",
      "Epoch 194/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1167 - binary_accuracy: 0.7500 - val_loss: 0.1163 - val_binary_accuracy: 0.7500\n",
      "Epoch 195/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1163 - binary_accuracy: 0.7500 - val_loss: 0.1159 - val_binary_accuracy: 0.7500\n",
      "Epoch 196/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1159 - binary_accuracy: 0.7500 - val_loss: 0.1155 - val_binary_accuracy: 0.7500\n",
      "Epoch 197/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1155 - binary_accuracy: 0.7500 - val_loss: 0.1151 - val_binary_accuracy: 0.7500\n",
      "Epoch 198/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1151 - binary_accuracy: 0.7500 - val_loss: 0.1146 - val_binary_accuracy: 0.7500\n",
      "Epoch 199/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1146 - binary_accuracy: 0.7500 - val_loss: 0.1142 - val_binary_accuracy: 0.7500\n",
      "Epoch 200/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1142 - binary_accuracy: 0.7500 - val_loss: 0.1138 - val_binary_accuracy: 0.7500\n",
      "Epoch 201/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1138 - binary_accuracy: 0.7500 - val_loss: 0.1134 - val_binary_accuracy: 0.7500\n",
      "Epoch 202/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1134 - binary_accuracy: 0.7500 - val_loss: 0.1129 - val_binary_accuracy: 0.7500\n",
      "Epoch 203/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1129 - binary_accuracy: 0.7500 - val_loss: 0.1125 - val_binary_accuracy: 0.7500\n",
      "Epoch 204/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1125 - binary_accuracy: 0.7500 - val_loss: 0.1121 - val_binary_accuracy: 0.7500\n",
      "Epoch 205/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1121 - binary_accuracy: 0.7500 - val_loss: 0.1117 - val_binary_accuracy: 0.7500\n",
      "Epoch 206/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1117 - binary_accuracy: 0.7500 - val_loss: 0.1112 - val_binary_accuracy: 0.7500\n",
      "Epoch 207/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1112 - binary_accuracy: 0.7500 - val_loss: 0.1108 - val_binary_accuracy: 0.7500\n",
      "Epoch 208/450\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1108 - binary_accuracy: 0.7500 - val_loss: 0.1104 - val_binary_accuracy: 0.7500\n",
      "Epoch 209/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1104 - binary_accuracy: 0.7500 - val_loss: 0.1100 - val_binary_accuracy: 0.7500\n",
      "Epoch 210/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1100 - binary_accuracy: 0.7500 - val_loss: 0.1095 - val_binary_accuracy: 0.7500\n",
      "Epoch 211/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1095 - binary_accuracy: 0.7500 - val_loss: 0.1091 - val_binary_accuracy: 0.7500\n",
      "Epoch 212/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1091 - binary_accuracy: 0.7500 - val_loss: 0.1087 - val_binary_accuracy: 0.7500\n",
      "Epoch 213/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1087 - binary_accuracy: 0.7500 - val_loss: 0.1082 - val_binary_accuracy: 0.7500\n",
      "Epoch 214/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1082 - binary_accuracy: 0.7500 - val_loss: 0.1078 - val_binary_accuracy: 0.7500\n",
      "Epoch 215/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1078 - binary_accuracy: 0.7500 - val_loss: 0.1074 - val_binary_accuracy: 0.7500\n",
      "Epoch 216/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1074 - binary_accuracy: 0.7500 - val_loss: 0.1069 - val_binary_accuracy: 0.7500\n",
      "Epoch 217/450\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1069 - binary_accuracy: 0.7500 - val_loss: 0.1065 - val_binary_accuracy: 0.7500\n",
      "Epoch 218/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1065 - binary_accuracy: 0.7500 - val_loss: 0.1061 - val_binary_accuracy: 0.7500\n",
      "Epoch 219/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1061 - binary_accuracy: 0.7500 - val_loss: 0.1056 - val_binary_accuracy: 0.7500\n",
      "Epoch 220/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1056 - binary_accuracy: 0.7500 - val_loss: 0.1052 - val_binary_accuracy: 0.7500\n",
      "Epoch 221/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1052 - binary_accuracy: 0.7500 - val_loss: 0.1047 - val_binary_accuracy: 0.7500\n",
      "Epoch 222/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1047 - binary_accuracy: 0.7500 - val_loss: 0.1043 - val_binary_accuracy: 0.7500\n",
      "Epoch 223/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1043 - binary_accuracy: 0.7500 - val_loss: 0.1039 - val_binary_accuracy: 0.7500\n",
      "Epoch 224/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1039 - binary_accuracy: 0.7500 - val_loss: 0.1034 - val_binary_accuracy: 0.7500\n",
      "Epoch 225/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1034 - binary_accuracy: 0.7500 - val_loss: 0.1030 - val_binary_accuracy: 0.7500\n",
      "Epoch 226/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1030 - binary_accuracy: 0.7500 - val_loss: 0.1025 - val_binary_accuracy: 0.7500\n",
      "Epoch 227/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1025 - binary_accuracy: 0.7500 - val_loss: 0.1021 - val_binary_accuracy: 0.7500\n",
      "Epoch 228/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1021 - binary_accuracy: 0.7500 - val_loss: 0.1016 - val_binary_accuracy: 0.7500\n",
      "Epoch 229/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1016 - binary_accuracy: 0.7500 - val_loss: 0.1012 - val_binary_accuracy: 0.7500\n",
      "Epoch 230/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1012 - binary_accuracy: 0.7500 - val_loss: 0.1007 - val_binary_accuracy: 0.7500\n",
      "Epoch 231/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1007 - binary_accuracy: 0.7500 - val_loss: 0.1003 - val_binary_accuracy: 0.7500\n",
      "Epoch 232/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1003 - binary_accuracy: 0.7500 - val_loss: 0.0999 - val_binary_accuracy: 0.7500\n",
      "Epoch 233/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0999 - binary_accuracy: 0.7500 - val_loss: 0.0996 - val_binary_accuracy: 0.7500\n",
      "Epoch 234/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0996 - binary_accuracy: 0.7500 - val_loss: 0.0992 - val_binary_accuracy: 0.7500\n",
      "Epoch 235/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0992 - binary_accuracy: 0.7500 - val_loss: 0.0990 - val_binary_accuracy: 0.7500\n",
      "Epoch 236/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0990 - binary_accuracy: 0.7500 - val_loss: 0.0986 - val_binary_accuracy: 0.7500\n",
      "Epoch 237/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0986 - binary_accuracy: 0.7500 - val_loss: 0.0984 - val_binary_accuracy: 0.7500\n",
      "Epoch 238/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0984 - binary_accuracy: 0.7500 - val_loss: 0.0980 - val_binary_accuracy: 0.7500\n",
      "Epoch 239/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0980 - binary_accuracy: 0.7500 - val_loss: 0.0978 - val_binary_accuracy: 1.0000\n",
      "Epoch 240/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0978 - binary_accuracy: 1.0000 - val_loss: 0.0974 - val_binary_accuracy: 0.7500\n",
      "Epoch 241/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0974 - binary_accuracy: 0.7500 - val_loss: 0.0972 - val_binary_accuracy: 1.0000\n",
      "Epoch 242/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0972 - binary_accuracy: 1.0000 - val_loss: 0.0968 - val_binary_accuracy: 0.7500\n",
      "Epoch 243/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0968 - binary_accuracy: 0.7500 - val_loss: 0.0966 - val_binary_accuracy: 1.0000\n",
      "Epoch 244/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0966 - binary_accuracy: 1.0000 - val_loss: 0.0962 - val_binary_accuracy: 1.0000\n",
      "Epoch 245/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0962 - binary_accuracy: 1.0000 - val_loss: 0.0959 - val_binary_accuracy: 1.0000\n",
      "Epoch 246/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0959 - binary_accuracy: 1.0000 - val_loss: 0.0956 - val_binary_accuracy: 1.0000\n",
      "Epoch 247/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0956 - binary_accuracy: 1.0000 - val_loss: 0.0953 - val_binary_accuracy: 1.0000\n",
      "Epoch 248/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0953 - binary_accuracy: 1.0000 - val_loss: 0.0951 - val_binary_accuracy: 1.0000\n",
      "Epoch 249/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0951 - binary_accuracy: 1.0000 - val_loss: 0.0947 - val_binary_accuracy: 1.0000\n",
      "Epoch 250/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0947 - binary_accuracy: 1.0000 - val_loss: 0.0945 - val_binary_accuracy: 1.0000\n",
      "Epoch 251/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0945 - binary_accuracy: 1.0000 - val_loss: 0.0942 - val_binary_accuracy: 1.0000\n",
      "Epoch 252/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0942 - binary_accuracy: 1.0000 - val_loss: 0.0939 - val_binary_accuracy: 1.0000\n",
      "Epoch 253/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0939 - binary_accuracy: 1.0000 - val_loss: 0.0936 - val_binary_accuracy: 1.0000\n",
      "Epoch 254/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0936 - binary_accuracy: 1.0000 - val_loss: 0.0932 - val_binary_accuracy: 1.0000\n",
      "Epoch 255/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0932 - binary_accuracy: 1.0000 - val_loss: 0.0931 - val_binary_accuracy: 1.0000\n",
      "Epoch 256/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0931 - binary_accuracy: 1.0000 - val_loss: 0.0927 - val_binary_accuracy: 1.0000\n",
      "Epoch 257/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0927 - binary_accuracy: 1.0000 - val_loss: 0.0925 - val_binary_accuracy: 1.0000\n",
      "Epoch 258/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0925 - binary_accuracy: 1.0000 - val_loss: 0.0922 - val_binary_accuracy: 1.0000\n",
      "Epoch 259/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0922 - binary_accuracy: 1.0000 - val_loss: 0.0919 - val_binary_accuracy: 1.0000\n",
      "Epoch 260/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0919 - binary_accuracy: 1.0000 - val_loss: 0.0917 - val_binary_accuracy: 1.0000\n",
      "Epoch 261/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0917 - binary_accuracy: 1.0000 - val_loss: 0.0912 - val_binary_accuracy: 1.0000\n",
      "Epoch 262/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0912 - binary_accuracy: 1.0000 - val_loss: 0.0910 - val_binary_accuracy: 1.0000\n",
      "Epoch 263/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0910 - binary_accuracy: 1.0000 - val_loss: 0.0907 - val_binary_accuracy: 1.0000\n",
      "Epoch 264/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0907 - binary_accuracy: 1.0000 - val_loss: 0.0903 - val_binary_accuracy: 1.0000\n",
      "Epoch 265/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0903 - binary_accuracy: 1.0000 - val_loss: 0.0901 - val_binary_accuracy: 1.0000\n",
      "Epoch 266/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0901 - binary_accuracy: 1.0000 - val_loss: 0.0897 - val_binary_accuracy: 1.0000\n",
      "Epoch 267/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0897 - binary_accuracy: 1.0000 - val_loss: 0.0895 - val_binary_accuracy: 1.0000\n",
      "Epoch 268/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0895 - binary_accuracy: 1.0000 - val_loss: 0.0892 - val_binary_accuracy: 1.0000\n",
      "Epoch 269/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0892 - binary_accuracy: 1.0000 - val_loss: 0.0888 - val_binary_accuracy: 1.0000\n",
      "Epoch 270/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0888 - binary_accuracy: 1.0000 - val_loss: 0.0887 - val_binary_accuracy: 1.0000\n",
      "Epoch 271/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0887 - binary_accuracy: 1.0000 - val_loss: 0.0883 - val_binary_accuracy: 1.0000\n",
      "Epoch 272/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0883 - binary_accuracy: 1.0000 - val_loss: 0.0881 - val_binary_accuracy: 1.0000\n",
      "Epoch 273/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0881 - binary_accuracy: 1.0000 - val_loss: 0.0878 - val_binary_accuracy: 1.0000\n",
      "Epoch 274/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0878 - binary_accuracy: 1.0000 - val_loss: 0.0874 - val_binary_accuracy: 1.0000\n",
      "Epoch 275/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0874 - binary_accuracy: 1.0000 - val_loss: 0.0873 - val_binary_accuracy: 1.0000\n",
      "Epoch 276/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0873 - binary_accuracy: 1.0000 - val_loss: 0.0870 - val_binary_accuracy: 1.0000\n",
      "Epoch 277/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0870 - binary_accuracy: 1.0000 - val_loss: 0.0866 - val_binary_accuracy: 1.0000\n",
      "Epoch 278/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0866 - binary_accuracy: 1.0000 - val_loss: 0.0864 - val_binary_accuracy: 1.0000\n",
      "Epoch 279/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0864 - binary_accuracy: 1.0000 - val_loss: 0.0860 - val_binary_accuracy: 1.0000\n",
      "Epoch 280/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0860 - binary_accuracy: 1.0000 - val_loss: 0.0857 - val_binary_accuracy: 1.0000\n",
      "Epoch 281/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0857 - binary_accuracy: 1.0000 - val_loss: 0.0854 - val_binary_accuracy: 1.0000\n",
      "Epoch 282/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0854 - binary_accuracy: 1.0000 - val_loss: 0.0851 - val_binary_accuracy: 1.0000\n",
      "Epoch 283/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0851 - binary_accuracy: 1.0000 - val_loss: 0.0849 - val_binary_accuracy: 1.0000\n",
      "Epoch 284/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0849 - binary_accuracy: 1.0000 - val_loss: 0.0845 - val_binary_accuracy: 1.0000\n",
      "Epoch 285/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0845 - binary_accuracy: 1.0000 - val_loss: 0.0842 - val_binary_accuracy: 1.0000\n",
      "Epoch 286/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0842 - binary_accuracy: 1.0000 - val_loss: 0.0840 - val_binary_accuracy: 1.0000\n",
      "Epoch 287/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0840 - binary_accuracy: 1.0000 - val_loss: 0.0836 - val_binary_accuracy: 1.0000\n",
      "Epoch 288/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0836 - binary_accuracy: 1.0000 - val_loss: 0.0834 - val_binary_accuracy: 1.0000\n",
      "Epoch 289/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0834 - binary_accuracy: 1.0000 - val_loss: 0.0831 - val_binary_accuracy: 1.0000\n",
      "Epoch 290/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0831 - binary_accuracy: 1.0000 - val_loss: 0.0828 - val_binary_accuracy: 1.0000\n",
      "Epoch 291/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0828 - binary_accuracy: 1.0000 - val_loss: 0.0827 - val_binary_accuracy: 1.0000\n",
      "Epoch 292/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0827 - binary_accuracy: 1.0000 - val_loss: 0.0823 - val_binary_accuracy: 1.0000\n",
      "Epoch 293/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0823 - binary_accuracy: 1.0000 - val_loss: 0.0820 - val_binary_accuracy: 1.0000\n",
      "Epoch 294/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0820 - binary_accuracy: 1.0000 - val_loss: 0.0817 - val_binary_accuracy: 1.0000\n",
      "Epoch 295/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0817 - binary_accuracy: 1.0000 - val_loss: 0.0813 - val_binary_accuracy: 1.0000\n",
      "Epoch 296/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0813 - binary_accuracy: 1.0000 - val_loss: 0.0811 - val_binary_accuracy: 1.0000\n",
      "Epoch 297/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0811 - binary_accuracy: 1.0000 - val_loss: 0.0808 - val_binary_accuracy: 1.0000\n",
      "Epoch 298/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0808 - binary_accuracy: 1.0000 - val_loss: 0.0805 - val_binary_accuracy: 1.0000\n",
      "Epoch 299/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0805 - binary_accuracy: 1.0000 - val_loss: 0.0803 - val_binary_accuracy: 1.0000\n",
      "Epoch 300/450\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0803 - binary_accuracy: 1.0000 - val_loss: 0.0799 - val_binary_accuracy: 1.0000\n",
      "Epoch 301/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0799 - binary_accuracy: 1.0000 - val_loss: 0.0796 - val_binary_accuracy: 1.0000\n",
      "Epoch 302/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0796 - binary_accuracy: 1.0000 - val_loss: 0.0793 - val_binary_accuracy: 1.0000\n",
      "Epoch 303/450\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0793 - binary_accuracy: 1.0000 - val_loss: 0.0790 - val_binary_accuracy: 1.0000\n",
      "Epoch 304/450\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0790 - binary_accuracy: 1.0000 - val_loss: 0.0788 - val_binary_accuracy: 1.0000\n",
      "Epoch 305/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0788 - binary_accuracy: 1.0000 - val_loss: 0.0785 - val_binary_accuracy: 1.0000\n",
      "Epoch 306/450\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0785 - binary_accuracy: 1.0000 - val_loss: 0.0782 - val_binary_accuracy: 1.0000\n",
      "Epoch 307/450\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0782 - binary_accuracy: 1.0000 - val_loss: 0.0780 - val_binary_accuracy: 1.0000\n",
      "Epoch 308/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0780 - binary_accuracy: 1.0000 - val_loss: 0.0776 - val_binary_accuracy: 1.0000\n",
      "Epoch 309/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0776 - binary_accuracy: 1.0000 - val_loss: 0.0773 - val_binary_accuracy: 1.0000\n",
      "Epoch 310/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0773 - binary_accuracy: 1.0000 - val_loss: 0.0770 - val_binary_accuracy: 1.0000\n",
      "Epoch 311/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0770 - binary_accuracy: 1.0000 - val_loss: 0.0766 - val_binary_accuracy: 1.0000\n",
      "Epoch 312/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0766 - binary_accuracy: 1.0000 - val_loss: 0.0765 - val_binary_accuracy: 1.0000\n",
      "Epoch 313/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0765 - binary_accuracy: 1.0000 - val_loss: 0.0761 - val_binary_accuracy: 1.0000\n",
      "Epoch 314/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0761 - binary_accuracy: 1.0000 - val_loss: 0.0758 - val_binary_accuracy: 1.0000\n",
      "Epoch 315/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0758 - binary_accuracy: 1.0000 - val_loss: 0.0757 - val_binary_accuracy: 1.0000\n",
      "Epoch 316/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0757 - binary_accuracy: 1.0000 - val_loss: 0.0753 - val_binary_accuracy: 1.0000\n",
      "Epoch 317/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0753 - binary_accuracy: 1.0000 - val_loss: 0.0749 - val_binary_accuracy: 1.0000\n",
      "Epoch 318/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0749 - binary_accuracy: 1.0000 - val_loss: 0.0747 - val_binary_accuracy: 1.0000\n",
      "Epoch 319/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0747 - binary_accuracy: 1.0000 - val_loss: 0.0744 - val_binary_accuracy: 1.0000\n",
      "Epoch 320/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0744 - binary_accuracy: 1.0000 - val_loss: 0.0741 - val_binary_accuracy: 1.0000\n",
      "Epoch 321/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0741 - binary_accuracy: 1.0000 - val_loss: 0.0739 - val_binary_accuracy: 1.0000\n",
      "Epoch 322/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0739 - binary_accuracy: 1.0000 - val_loss: 0.0735 - val_binary_accuracy: 1.0000\n",
      "Epoch 323/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0735 - binary_accuracy: 1.0000 - val_loss: 0.0733 - val_binary_accuracy: 1.0000\n",
      "Epoch 324/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0733 - binary_accuracy: 1.0000 - val_loss: 0.0730 - val_binary_accuracy: 1.0000\n",
      "Epoch 325/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0730 - binary_accuracy: 1.0000 - val_loss: 0.0726 - val_binary_accuracy: 1.0000\n",
      "Epoch 326/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0726 - binary_accuracy: 1.0000 - val_loss: 0.0724 - val_binary_accuracy: 1.0000\n",
      "Epoch 327/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0724 - binary_accuracy: 1.0000 - val_loss: 0.0721 - val_binary_accuracy: 1.0000\n",
      "Epoch 328/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0721 - binary_accuracy: 1.0000 - val_loss: 0.0718 - val_binary_accuracy: 1.0000\n",
      "Epoch 329/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0718 - binary_accuracy: 1.0000 - val_loss: 0.0716 - val_binary_accuracy: 1.0000\n",
      "Epoch 330/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0716 - binary_accuracy: 1.0000 - val_loss: 0.0712 - val_binary_accuracy: 1.0000\n",
      "Epoch 331/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0712 - binary_accuracy: 1.0000 - val_loss: 0.0710 - val_binary_accuracy: 1.0000\n",
      "Epoch 332/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0710 - binary_accuracy: 1.0000 - val_loss: 0.0707 - val_binary_accuracy: 1.0000\n",
      "Epoch 333/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0707 - binary_accuracy: 1.0000 - val_loss: 0.0703 - val_binary_accuracy: 1.0000\n",
      "Epoch 334/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0703 - binary_accuracy: 1.0000 - val_loss: 0.0702 - val_binary_accuracy: 1.0000\n",
      "Epoch 335/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0702 - binary_accuracy: 1.0000 - val_loss: 0.0698 - val_binary_accuracy: 1.0000\n",
      "Epoch 336/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0698 - binary_accuracy: 1.0000 - val_loss: 0.0695 - val_binary_accuracy: 1.0000\n",
      "Epoch 337/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0695 - binary_accuracy: 1.0000 - val_loss: 0.0694 - val_binary_accuracy: 1.0000\n",
      "Epoch 338/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0694 - binary_accuracy: 1.0000 - val_loss: 0.0689 - val_binary_accuracy: 1.0000\n",
      "Epoch 339/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0689 - binary_accuracy: 1.0000 - val_loss: 0.0686 - val_binary_accuracy: 1.0000\n",
      "Epoch 340/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0686 - binary_accuracy: 1.0000 - val_loss: 0.0684 - val_binary_accuracy: 1.0000\n",
      "Epoch 341/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0684 - binary_accuracy: 1.0000 - val_loss: 0.0680 - val_binary_accuracy: 1.0000\n",
      "Epoch 342/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0680 - binary_accuracy: 1.0000 - val_loss: 0.0678 - val_binary_accuracy: 1.0000\n",
      "Epoch 343/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0678 - binary_accuracy: 1.0000 - val_loss: 0.0675 - val_binary_accuracy: 1.0000\n",
      "Epoch 344/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0675 - binary_accuracy: 1.0000 - val_loss: 0.0672 - val_binary_accuracy: 1.0000\n",
      "Epoch 345/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0672 - binary_accuracy: 1.0000 - val_loss: 0.0669 - val_binary_accuracy: 1.0000\n",
      "Epoch 346/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0669 - binary_accuracy: 1.0000 - val_loss: 0.0671 - val_binary_accuracy: 1.0000\n",
      "Epoch 347/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0671 - binary_accuracy: 1.0000 - val_loss: 0.0667 - val_binary_accuracy: 1.0000\n",
      "Epoch 348/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0667 - binary_accuracy: 1.0000 - val_loss: 0.0663 - val_binary_accuracy: 1.0000\n",
      "Epoch 349/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0663 - binary_accuracy: 1.0000 - val_loss: 0.0661 - val_binary_accuracy: 1.0000\n",
      "Epoch 350/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0661 - binary_accuracy: 1.0000 - val_loss: 0.0660 - val_binary_accuracy: 1.0000\n",
      "Epoch 351/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0660 - binary_accuracy: 1.0000 - val_loss: 0.0657 - val_binary_accuracy: 1.0000\n",
      "Epoch 352/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0657 - binary_accuracy: 1.0000 - val_loss: 0.0654 - val_binary_accuracy: 1.0000\n",
      "Epoch 353/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0654 - binary_accuracy: 1.0000 - val_loss: 0.0656 - val_binary_accuracy: 1.0000\n",
      "Epoch 354/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0656 - binary_accuracy: 1.0000 - val_loss: 0.0651 - val_binary_accuracy: 1.0000\n",
      "Epoch 355/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0651 - binary_accuracy: 1.0000 - val_loss: 0.0649 - val_binary_accuracy: 1.0000\n",
      "Epoch 356/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0649 - binary_accuracy: 1.0000 - val_loss: 0.0648 - val_binary_accuracy: 1.0000\n",
      "Epoch 357/450\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0648 - binary_accuracy: 1.0000 - val_loss: 0.0644 - val_binary_accuracy: 1.0000\n",
      "Epoch 358/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0644 - binary_accuracy: 1.0000 - val_loss: 0.0641 - val_binary_accuracy: 1.0000\n",
      "Epoch 359/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0641 - binary_accuracy: 1.0000 - val_loss: 0.0642 - val_binary_accuracy: 1.0000\n",
      "Epoch 360/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0642 - binary_accuracy: 1.0000 - val_loss: 0.0639 - val_binary_accuracy: 1.0000\n",
      "Epoch 361/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0639 - binary_accuracy: 1.0000 - val_loss: 0.0636 - val_binary_accuracy: 1.0000\n",
      "Epoch 362/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0636 - binary_accuracy: 1.0000 - val_loss: 0.0637 - val_binary_accuracy: 1.0000\n",
      "Epoch 363/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0637 - binary_accuracy: 1.0000 - val_loss: 0.0631 - val_binary_accuracy: 1.0000\n",
      "Epoch 364/450\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0631 - binary_accuracy: 1.0000 - val_loss: 0.0630 - val_binary_accuracy: 1.0000\n",
      "Epoch 365/450\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0630 - binary_accuracy: 1.0000 - val_loss: 0.0628 - val_binary_accuracy: 1.0000\n",
      "Epoch 366/450\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0628 - binary_accuracy: 1.0000 - val_loss: 0.0625 - val_binary_accuracy: 1.0000\n",
      "Epoch 367/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0625 - binary_accuracy: 1.0000 - val_loss: 0.0622 - val_binary_accuracy: 1.0000\n",
      "Epoch 368/450\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0622 - binary_accuracy: 1.0000 - val_loss: 0.0621 - val_binary_accuracy: 1.0000\n",
      "Epoch 369/450\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0621 - binary_accuracy: 1.0000 - val_loss: 0.0619 - val_binary_accuracy: 1.0000\n",
      "Epoch 370/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0619 - binary_accuracy: 1.0000 - val_loss: 0.0618 - val_binary_accuracy: 1.0000\n",
      "Epoch 371/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0618 - binary_accuracy: 1.0000 - val_loss: 0.0615 - val_binary_accuracy: 1.0000\n",
      "Epoch 372/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0615 - binary_accuracy: 1.0000 - val_loss: 0.0612 - val_binary_accuracy: 1.0000\n",
      "Epoch 373/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0612 - binary_accuracy: 1.0000 - val_loss: 0.0613 - val_binary_accuracy: 1.0000\n",
      "Epoch 374/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0613 - binary_accuracy: 1.0000 - val_loss: 0.0610 - val_binary_accuracy: 1.0000\n",
      "Epoch 375/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0610 - binary_accuracy: 1.0000 - val_loss: 0.0607 - val_binary_accuracy: 1.0000\n",
      "Epoch 376/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0607 - binary_accuracy: 1.0000 - val_loss: 0.0607 - val_binary_accuracy: 1.0000\n",
      "Epoch 377/450\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0607 - binary_accuracy: 1.0000 - val_loss: 0.0602 - val_binary_accuracy: 1.0000\n",
      "Epoch 378/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0602 - binary_accuracy: 1.0000 - val_loss: 0.0600 - val_binary_accuracy: 1.0000\n",
      "Epoch 379/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0600 - binary_accuracy: 1.0000 - val_loss: 0.0599 - val_binary_accuracy: 1.0000\n",
      "Epoch 380/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0599 - binary_accuracy: 1.0000 - val_loss: 0.0595 - val_binary_accuracy: 1.0000\n",
      "Epoch 381/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0595 - binary_accuracy: 1.0000 - val_loss: 0.0593 - val_binary_accuracy: 1.0000\n",
      "Epoch 382/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0593 - binary_accuracy: 1.0000 - val_loss: 0.0591 - val_binary_accuracy: 1.0000\n",
      "Epoch 383/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0591 - binary_accuracy: 1.0000 - val_loss: 0.0590 - val_binary_accuracy: 1.0000\n",
      "Epoch 384/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0590 - binary_accuracy: 1.0000 - val_loss: 0.0588 - val_binary_accuracy: 1.0000\n",
      "Epoch 385/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0588 - binary_accuracy: 1.0000 - val_loss: 0.0587 - val_binary_accuracy: 1.0000\n",
      "Epoch 386/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0587 - binary_accuracy: 1.0000 - val_loss: 0.0583 - val_binary_accuracy: 1.0000\n",
      "Epoch 387/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0583 - binary_accuracy: 1.0000 - val_loss: 0.0582 - val_binary_accuracy: 1.0000\n",
      "Epoch 388/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0582 - binary_accuracy: 1.0000 - val_loss: 0.0580 - val_binary_accuracy: 1.0000\n",
      "Epoch 389/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0580 - binary_accuracy: 1.0000 - val_loss: 0.0577 - val_binary_accuracy: 1.0000\n",
      "Epoch 390/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0577 - binary_accuracy: 1.0000 - val_loss: 0.0577 - val_binary_accuracy: 1.0000\n",
      "Epoch 391/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0577 - binary_accuracy: 1.0000 - val_loss: 0.0572 - val_binary_accuracy: 1.0000\n",
      "Epoch 392/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0572 - binary_accuracy: 1.0000 - val_loss: 0.0572 - val_binary_accuracy: 1.0000\n",
      "Epoch 393/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0572 - binary_accuracy: 1.0000 - val_loss: 0.0570 - val_binary_accuracy: 1.0000\n",
      "Epoch 394/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0570 - binary_accuracy: 1.0000 - val_loss: 0.0566 - val_binary_accuracy: 1.0000\n",
      "Epoch 395/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0566 - binary_accuracy: 1.0000 - val_loss: 0.0564 - val_binary_accuracy: 1.0000\n",
      "Epoch 396/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0564 - binary_accuracy: 1.0000 - val_loss: 0.0562 - val_binary_accuracy: 1.0000\n",
      "Epoch 397/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0562 - binary_accuracy: 1.0000 - val_loss: 0.0560 - val_binary_accuracy: 1.0000\n",
      "Epoch 398/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0560 - binary_accuracy: 1.0000 - val_loss: 0.0560 - val_binary_accuracy: 1.0000\n",
      "Epoch 399/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0560 - binary_accuracy: 1.0000 - val_loss: 0.0556 - val_binary_accuracy: 1.0000\n",
      "Epoch 400/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0556 - binary_accuracy: 1.0000 - val_loss: 0.0554 - val_binary_accuracy: 1.0000\n",
      "Epoch 401/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0554 - binary_accuracy: 1.0000 - val_loss: 0.0554 - val_binary_accuracy: 1.0000\n",
      "Epoch 402/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0554 - binary_accuracy: 1.0000 - val_loss: 0.0552 - val_binary_accuracy: 1.0000\n",
      "Epoch 403/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0552 - binary_accuracy: 1.0000 - val_loss: 0.0548 - val_binary_accuracy: 1.0000\n",
      "Epoch 404/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0548 - binary_accuracy: 1.0000 - val_loss: 0.0549 - val_binary_accuracy: 1.0000\n",
      "Epoch 405/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0549 - binary_accuracy: 1.0000 - val_loss: 0.0543 - val_binary_accuracy: 1.0000\n",
      "Epoch 406/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0543 - binary_accuracy: 1.0000 - val_loss: 0.0542 - val_binary_accuracy: 1.0000\n",
      "Epoch 407/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0542 - binary_accuracy: 1.0000 - val_loss: 0.0541 - val_binary_accuracy: 1.0000\n",
      "Epoch 408/450\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0541 - binary_accuracy: 1.0000 - val_loss: 0.0536 - val_binary_accuracy: 1.0000\n",
      "Epoch 409/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0536 - binary_accuracy: 1.0000 - val_loss: 0.0535 - val_binary_accuracy: 1.0000\n",
      "Epoch 410/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0535 - binary_accuracy: 1.0000 - val_loss: 0.0533 - val_binary_accuracy: 1.0000\n",
      "Epoch 411/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0533 - binary_accuracy: 1.0000 - val_loss: 0.0531 - val_binary_accuracy: 1.0000\n",
      "Epoch 412/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0531 - binary_accuracy: 1.0000 - val_loss: 0.0531 - val_binary_accuracy: 1.0000\n",
      "Epoch 413/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0531 - binary_accuracy: 1.0000 - val_loss: 0.0527 - val_binary_accuracy: 1.0000\n",
      "Epoch 414/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0527 - binary_accuracy: 1.0000 - val_loss: 0.0525 - val_binary_accuracy: 1.0000\n",
      "Epoch 415/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0525 - binary_accuracy: 1.0000 - val_loss: 0.0525 - val_binary_accuracy: 1.0000\n",
      "Epoch 416/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0525 - binary_accuracy: 1.0000 - val_loss: 0.0523 - val_binary_accuracy: 1.0000\n",
      "Epoch 417/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0523 - binary_accuracy: 1.0000 - val_loss: 0.0519 - val_binary_accuracy: 1.0000\n",
      "Epoch 418/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0519 - binary_accuracy: 1.0000 - val_loss: 0.0517 - val_binary_accuracy: 1.0000\n",
      "Epoch 419/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0517 - binary_accuracy: 1.0000 - val_loss: 0.0516 - val_binary_accuracy: 1.0000\n",
      "Epoch 420/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0516 - binary_accuracy: 1.0000 - val_loss: 0.0515 - val_binary_accuracy: 1.0000\n",
      "Epoch 421/450\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0515 - binary_accuracy: 1.0000 - val_loss: 0.0511 - val_binary_accuracy: 1.0000\n",
      "Epoch 422/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0511 - binary_accuracy: 1.0000 - val_loss: 0.0508 - val_binary_accuracy: 1.0000\n",
      "Epoch 423/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0508 - binary_accuracy: 1.0000 - val_loss: 0.0509 - val_binary_accuracy: 1.0000\n",
      "Epoch 424/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0509 - binary_accuracy: 1.0000 - val_loss: 0.0506 - val_binary_accuracy: 1.0000\n",
      "Epoch 425/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0506 - binary_accuracy: 1.0000 - val_loss: 0.0503 - val_binary_accuracy: 1.0000\n",
      "Epoch 426/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0503 - binary_accuracy: 1.0000 - val_loss: 0.0503 - val_binary_accuracy: 1.0000\n",
      "Epoch 427/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0503 - binary_accuracy: 1.0000 - val_loss: 0.0498 - val_binary_accuracy: 1.0000\n",
      "Epoch 428/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0498 - binary_accuracy: 1.0000 - val_loss: 0.0498 - val_binary_accuracy: 1.0000\n",
      "Epoch 429/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0498 - binary_accuracy: 1.0000 - val_loss: 0.0495 - val_binary_accuracy: 1.0000\n",
      "Epoch 430/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0495 - binary_accuracy: 1.0000 - val_loss: 0.0492 - val_binary_accuracy: 1.0000\n",
      "Epoch 431/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0492 - binary_accuracy: 1.0000 - val_loss: 0.0490 - val_binary_accuracy: 1.0000\n",
      "Epoch 432/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0490 - binary_accuracy: 1.0000 - val_loss: 0.0488 - val_binary_accuracy: 1.0000\n",
      "Epoch 433/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0488 - binary_accuracy: 1.0000 - val_loss: 0.0486 - val_binary_accuracy: 1.0000\n",
      "Epoch 434/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0486 - binary_accuracy: 1.0000 - val_loss: 0.0486 - val_binary_accuracy: 1.0000\n",
      "Epoch 435/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0486 - binary_accuracy: 1.0000 - val_loss: 0.0482 - val_binary_accuracy: 1.0000\n",
      "Epoch 436/450\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0482 - binary_accuracy: 1.0000 - val_loss: 0.0480 - val_binary_accuracy: 1.0000\n",
      "Epoch 437/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0480 - binary_accuracy: 1.0000 - val_loss: 0.0480 - val_binary_accuracy: 1.0000\n",
      "Epoch 438/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0480 - binary_accuracy: 1.0000 - val_loss: 0.0478 - val_binary_accuracy: 1.0000\n",
      "Epoch 439/450\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0478 - binary_accuracy: 1.0000 - val_loss: 0.0474 - val_binary_accuracy: 1.0000\n",
      "Epoch 440/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0474 - binary_accuracy: 1.0000 - val_loss: 0.0472 - val_binary_accuracy: 1.0000\n",
      "Epoch 441/450\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0472 - binary_accuracy: 1.0000 - val_loss: 0.0471 - val_binary_accuracy: 1.0000\n",
      "Epoch 442/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0471 - binary_accuracy: 1.0000 - val_loss: 0.0470 - val_binary_accuracy: 1.0000\n",
      "Epoch 443/450\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0470 - binary_accuracy: 1.0000 - val_loss: 0.0467 - val_binary_accuracy: 1.0000\n",
      "Epoch 444/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0467 - binary_accuracy: 1.0000 - val_loss: 0.0464 - val_binary_accuracy: 1.0000\n",
      "Epoch 445/450\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0464 - binary_accuracy: 1.0000 - val_loss: 0.0464 - val_binary_accuracy: 1.0000\n",
      "Epoch 446/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0464 - binary_accuracy: 1.0000 - val_loss: 0.0461 - val_binary_accuracy: 1.0000\n",
      "Epoch 447/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0461 - binary_accuracy: 1.0000 - val_loss: 0.0458 - val_binary_accuracy: 1.0000\n",
      "Epoch 448/450\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0458 - binary_accuracy: 1.0000 - val_loss: 0.0459 - val_binary_accuracy: 1.0000\n",
      "Epoch 449/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0459 - binary_accuracy: 1.0000 - val_loss: 0.0454 - val_binary_accuracy: 1.0000\n",
      "Epoch 450/450\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0454 - binary_accuracy: 1.0000 - val_loss: 0.0453 - val_binary_accuracy: 1.0000\n",
      "Minimum Validation Loss: 0.04529\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "from graphviz import Source\n",
    "\n",
    "# initially I got val loss 0.07 because Id column present. After removing it I got 0.13\n",
    "# Then I experimented with optimizers, loss and activation functions and the number of layers and neurons and finally got it back to 0.0700\n",
    "\n",
    "# activation_function = 'relu'\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Activation\n",
    "# from keras.utils.generic_utils import get_custom_objects\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "### Note! You cannot use random python functions, activation function gets as an input tensorflow tensors and should return tensors. There are a lot of helper functions in keras backend.\n",
    "# def custom_activation(x_):\n",
    "#     res = tf.nn.sigmoid(x_)\n",
    "#     return tf.round(res)\n",
    "\n",
    "# from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "#\n",
    "# model.add(layers.Dense(64))\n",
    "# model.add(layers.Activation(activations.relu))\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=Activation(activations.relu), input_shape=input_shape))\n",
    "model.add(layers.Dense(8, activation=Activation(activations.relu)))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "accuracy = tf.keras.metrics.BinaryAccuracy(\n",
    "    name=\"binary_accuracy\", dtype=None, threshold=0.5\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    # optimizer='adam',\n",
    "    #  loss='mae',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[accuracy]\n",
    "    # metrics=['binary_accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=4,# grupy danych\n",
    "    epochs=450,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "# print(model.summary())\n",
    "\n",
    "# ann_viz(model, title=\"XOR\")\n",
    "# graph = Source.from_file('network.gv')\n",
    "# graph\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(\"Minimum Validation Loss: {:0.5f}\".format(history_df['val_loss'].min()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 16:41:20.298023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 396ms/step\n",
      "[[0.99569964]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[0, 1]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:  [[-0.27461684  0.4068294   0.1928472  -0.764203    0.35078067 -0.16624615\n",
      "  -0.3127487   0.6648457 ]\n",
      " [ 0.42856586  0.5435925  -0.5195019  -0.56629664 -0.5696406   0.03136323\n",
      "   0.06463775  0.46979406]]\n",
      "biases:  [-0.2760448   0.00713178 -0.09575146  0.         -0.0966637  -0.02278913\n",
      " -0.04582638  0.00670292]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df.loc[109:, ['loss', 'val_loss']].plot()\n",
    "weights = model.layers[1].get_weights()[0]\n",
    "biases = model.layers[1].get_weights()[1]\n",
    "print('weights: ', weights)\n",
    "print('biases: ', biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: max_pool. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# print(tf.__version__)\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m activation_layer \u001B[38;5;241m=\u001B[39m \u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mActivation\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_pool\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m100\u001B[39m)\n\u001B[1;32m     12\u001B[0m y \u001B[38;5;241m=\u001B[39m activation_layer(x)  \u001B[38;5;66;03m# once created, a layer is callable just like a function\u001B[39;00m\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/keras/layers/core/activation.py:54\u001B[0m, in \u001B[0;36mActivation.__init__\u001B[0;34m(self, activation, **kwargs)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28msuper\u001B[39m(Activation, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_masking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation \u001B[38;5;241m=\u001B[39m \u001B[43mactivations\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mactivation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/keras/activations.py:595\u001B[0m, in \u001B[0;36mget\u001B[0;34m(identifier)\u001B[0m\n\u001B[1;32m    593\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m linear\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(identifier, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mdict\u001B[39m)):\n\u001B[0;32m--> 595\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdeserialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43midentifier\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    596\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m callable(identifier):\n\u001B[1;32m    597\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m identifier\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/keras/activations.py:555\u001B[0m, in \u001B[0;36mdeserialize\u001B[0;34m(name, custom_objects)\u001B[0m\n\u001B[1;32m    552\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m globs:\n\u001B[1;32m    553\u001B[0m     globs[key] \u001B[38;5;241m=\u001B[39m val\n\u001B[0;32m--> 555\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdeserialize_keras_object\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    557\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodule_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mglobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprintable_module_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mactivation function\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/git/machine_learning/env/lib/python3.9/site-packages/keras/utils/generic_utils.py:709\u001B[0m, in \u001B[0;36mdeserialize_keras_object\u001B[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[1;32m    707\u001B[0m   obj \u001B[38;5;241m=\u001B[39m module_objects\u001B[38;5;241m.\u001B[39mget(object_name)\n\u001B[1;32m    708\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 709\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    710\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnknown \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprintable_module_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobject_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Please ensure \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    711\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthis object is passed to the `custom_objects` argument. See \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    712\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    713\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#registering_the_custom_object for details.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# returned as-is.\u001B[39;00m\n\u001B[1;32m    717\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf_inspect\u001B[38;5;241m.\u001B[39misclass(obj):\n",
      "\u001B[0;31mValueError\u001B[0m: Unknown activation function: max_pool. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# Change 'relu' to 'elu', 'selu', 'swish', sigmoid... or something else\n",
    "# How different activation functions look like\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print(tf.__version__)\n",
    "\n",
    "activation_layer = layers.Activation('max_pool')\n",
    "\n",
    "x = tf.linspace(-3.0, 3.0, 100)\n",
    "y = activation_layer(x)  # once created, a layer is callable just like a function\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(x, y)\n",
    "plt.xlim(-3, 3)\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}